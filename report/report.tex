\documentclass[conference]{IEEEtran}

\ifCLASSINFOpdf

\else

\fi


\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage[acronym]{glossaries}
\usepackage[backend=bibtex, style=ieee]{biblatex}

\addbibresource{bibliography}
% decomment below to reduce bib font size
% \renewcommand*{\bibfont}{\small}

% acronyms
\newacronym[plural=EAs, firstplural=Evolutionary Algorithms (EAs)]{ea}{EA}{Evolutionary Algorithm}
\newacronym{er}{ER}{Evolutionary Robotics}
\newacronym[plural=NNs, firstplural=Neural Networks]{nn}{NN}{Neural Network}
\newacronym[plural=ANNs, firstplural=Artificial Neural Networks]{ann}{ANN}{Artificial Neural Network}
\newacronym{tweann}{TWEANN}{Topology \& Weight Evolving Artificial Neural Network}
\newacronym{neat}{NEAT}{NeuroEvolution of Augmenting Topologies}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
 
\title{Competitive co-evolution in robots: \\ heterogeneity vs homogeneity}



\author{\IEEEauthorblockN{Selene Baez Santamaria, Andrea Jemmett, Tommie Kerstens, Enrico Rotundo}
\IEEEauthorblockA{
Vrije Universiteit Amsterdam \\
Amsterdam, Netherlands}}



\maketitle


\begin{abstract}
In the context of robotics, intelligent behaviours are often achieved using neural networks as controllers evolved using  an evolutionary algorithm.
In the case of multiple individuals within a species, controllers can be either homogeneous or heterogeneous.
In this paper, we use competitive co-evolution of homogeneous and heterogeneous controllers in order to investigate its effects on the emergence of specialisation behaviour regarding a herding task.

TODO: add what we have discovered!!!!!!!
% TODO: add what we have discovered
\end{abstract}


\IEEEpeerreviewmaketitle


\section{Introduction}
% Evolutionary Algorithms
\glspl{ea} are biology inspired algorithms that, going through multiple steps (reproduction, mutation, recombination and selection), are able to evolve entities over time.
Thus, the entities subject to the evolution are referred to as individuals and represent a candidate solution to an optimization problem.
An \gls{ea} measures the quality of individuals using a \textit{fitness function} and its aim is to improve individuals' fitness score along successive generations.
\gls{er} is a technique that uses \gls{ea}s to develop a policy for an autonomous robot.
Its main objective is to evolve intelligent robots behaviours required to solve some real-word task.
\gls{er} implementations often rely on an \gls{ann} to represent their controllers.
% Neural Networks
An \gls{ann}, commonly referred to as \gls{nn} in this field, is a function estimator that can be used as a policy for an autonomous agent and its design is natural inspired by the biological nervous system.
In order to employ it as a controller, inputs usually come from sensors making observations of the environment and the output is then used to control an actuation schema.
The evaluation of the individuals' controllers can be made in a simulation.
This exploits the computer's computational power in order to evaluate many individuals in a reasonable time frame.

% Solvable tasks
Tasks composition and complexity can vary based on specific scenarios, in general it is the subject of many studies aiming to solve different tasks.
For instance, tasks can be relatively small (e.g., moving objects) or more based on collaboration between a number of individuals.
Research investigates collective behaviour in order to asses to which extent collaboration between individuals is feasible.  

% Our task/paper
In this paper, we consider competitive co-evolution within a herding task which consists of a number of shepherds that herd a sheep into a corral.
We evolve \gls{nn} controllers and assign them to the agents, the latter step can be done with a homogeneous or heterogeneous approach.
While the former employs the same controller instance for each agent,
in the latter each agent gets its own instance of a controller, which is separately evolved by an \gls{ea}.
Moreover, the task complexity can be increased by varying or introducing new agents like adding a fox.

In this paper we employ the aforementioned components within a simulated herding task.
We recap our objectives in the following list:

\begin{itemize}
	\item To compare homogeneity versus heterogeneity.
	\item To estimate the effect on homo versus heterogeneity of increasingly difficult task.
 	\item To develop controlled experiments through software simulations, using ad hoc libraries.
	\item To collect comprehensive results data.
\end{itemize}
 
\subsection{Research questions}
\label{sec:researchQuestions}
In the herding task, shepherds and sheep have opposing goals.
While the former tries to herd sheep into a corral, the latter tries to escape through the left side of the pasture. 
Species can be competitively co-evolved in a race to evolve strategies to accomplish opposing goals. 
Furthermore, the task complexity can be influenced by varying different parameters such as the number of present agents per each type or their relative movement speeds. 
Another type of dimension used to scale the difficulty is the type of controllers used,
Instances of different controller types can be either \textit{static} or \textit{intelligent}.
A \textit{static} controller is simply a predefined set of rules that implements a specific behaviour.
Although an \textit{intelligent} controller is more complex due to its ability to adept itself over time.
In this paper both the sheep and the shepherds have an \textit{intelligent} controller.
The intelligence of the controller is based on the assumption that the \gls{nn} is evolved, and thus, the controller has the possibility to adapt to its environment through an evolutionary process. 
This process, in which many strategies are simulated and evaluated, is comparable to a learning process and enables adaptivity. 
Assuming an intelligent sheep we state the following research questions:

\begin{enumerate}
	\item How do homogeneous and heterogeneous shepherd controllers compare in a competitive co-evolved herding task?
	\item How does increasing the number of shepherds increase the need for heterogeneous controllers?
	\item How does increasing task complexity (by adding more sheep) affect the effectiveness of herding?
\end{enumerate}

\subsection{Hypothesis}
\label{sec:hypothesis}
The following hypothesis are in one to one relationship with the aforementioned research questions:

\begin{enumerate}
	\item Shepherds' fitness in the heterogeneous case is overall higher than in the homogeneous case.
	\item The number of shepherds herding one sheep is directly related to their fitness in heterogeneous cases, such that fitness increases as the number of shepherds increases.	
	\item Increasing the number of sheep herd by a fixed number of shepherds decreases the number of corralled sheep.
\end{enumerate}
$H_0$, namely the null hypothesis, is ``Shepherds' fitness in the heterogeneous case is equivalent to the one of the homogeneous''.
%TODO: add null hyptoesis for H_2 and H_3

\subsection{Contributions}
In this paper we introduce our proposed model for running a herding task in a competitive co-evolution framework. 
We have built our model and run a thorough set of simulations in order to test the hypothesis detailed in Section~\ref{sec:hypothesis}. 
In what follows, we list the main contributions of this paper to the state-of-the-art:
\textbf{TODO}
\begin{itemize}
	\item BLA
	\item PIZZA
	\item PASTA
	\item NESPRESSO....what else?
\end{itemize}

This work sheds a tiny light in the topic of competitive co-evolution by showing to which extent it is feasible in a herding task accomplished by robots.

\subsection{Organization}
The rest of this paper is organized as follows. 
In Section \ref{sec:lit_review}, we revise the state-of-the-art related to our research topic. 
In Section \ref{sec:model_design}, we present our model, describing its different components. 
We evaluate the performance of our solution in Section \ref{sec:experiment}. 
Finally, in Section \ref{sec:conclusion} we draw some conclusions and point out ways to further extend this work.

\section{Literature review}
\label{sec:lit_review}
In this Section, we survey the main researches in related work, considering the following topics: \textit{co-evolution}, \textit{\acrlong{er} \& neuroevolution} and \textit{homogeneous \& heterogeneous controllers}.
 
\subsection{Co-evolution}
Co-evolution in its foundation is a natural phenomena.
It describes how the basic principles of evolution are propagated through a dynamic process in which species not only evolve due to the selection pressure produced by an environment, but also due to the selection pressure produced as a by-product of other species evolving within that same environment.
The effects of co-evolution in butterflies and plants have been studied as early as 1964 in ~\cite{ehrlich1964butterflies}.
Furthermore, the authors of ~\cite{janzen1980coevolution} define co-evolution as ``an evolutionary change in a trait of the individuals in one population in response to a trait of the individuals of a second population''. 
%In 1980 Janzen's \cite{janzen1980coevolution} formalised a clear definition for coevolution:
%`` 'Coevolution' may be usefully defined as an evolutionary change in a trait of the individuals in one population in response to a trait of the individuals of a second population, followed by an evolutionary response by the second populations to the change in the first.''

% forms of co-evolution
Co-evolution may be deployed, as described in \cite{eiben2003introduction}, in two different forms: \textit{cooperative} and \textit{competitive}.
% cooperative co-evolution
In cooperative co-evolution, different species are evolved, each representing part of the solution to a problem.
The individuals in each species have to cooperate in order to come to a solution to a larger problem.
The advantage of this approach is that it permits a functional decomposition of the task to be solved.
% competitive co-evolution
In the competitive co-evolution mode, individuals compete against each other in an environment with limited resources, with the aim to increase its fitness at the expense of other's.
With more than one species, it is possible to let entire species compete against each other.
Competitive co-evolution has the advantage of creating selection pressure.
The individuals have to adapt to a more and more challenging opponent, so that the fitness landscape changes over time and hopefully becomes harsher to optimize.
\citeauthor{dawkins1979arms} describe in~\cite{dawkins1979arms} the dynamics and terminology for competitive co-evolution by providing examples of manifestations of competitive co-evolution in natural systems. 
The paper captures the pure essential of competitive co-evolution giving the following description: ``An adaptation in one lineage (e.g. predators) may change the selection pressure on another lineage (e.g. prey), giving rise to a counter-adaptation. If this occurs reciprocally, an unstable runaway escalation or 'arms race' may result''.

\subsection{\acrlong{er} \& Neuroevolution}
% Evolutionary Robotics
\citeauthor{nolfi2000evolutionary} in \cite{nolfi2000evolutionary}, define \gls{er} as a method for automatic creation of autonomous robots, following the Darwinian principle of selective reproduction of the fittest.
The term \acrlong{er} was firstly introduced in \cite{cli1993evolving}, but between 1992 and 1993, other two research groups reported promising results on artificial evolution of autonomous robots in \cite{lewis1992genetic} and \cite{nolfi1994evolve}.
\gls{er} can be implemented in simulation or in the physical world.
In simulation, \gls{er} is able to fast-forwarding time and make the entire process faster than running on real robots.
Unfortunately evolution of physical entities in a virtual world may suffer from a \textit{reality gap} when the controllers are deployed in physical robots, as thoroughly investigated in \cite{jakobi1995noise}.
By using physical robots, \gls{er} is able to bridge the reality gap but at expenses of deployment time

% Neuroevolution
\textit{Neuroevolution} is a set of techniques that uses \glspl{ea} to train an \gls{ann}.
It is widely applied in domain where an exhaustive mapping of the correct input and output is hard to define.
Therefore neuroevolution uses only the performance at the task to train a network (e.g. the fitness score).
\citeauthor{floreano2008neuroevolution} in \cite{floreano2008neuroevolution} classify three classes of genetic encoding of an \gls{ann}: direct, developmental and implicit.
This genetic encoding may represent not only the synaptic weights of the network, but also its topology.
The algorithms that evolve the network's topology and its parameters simultaneously are called \gls{tweann} algorithms.
% get some paper showing simple evolution of NNs
Neuroevolution has been applied with success in different domains such as video games \cite{hausknecht2014neuroevolution, stanley2005real}, collective self-organization \cite{nitschke2008neuro, nitschke2010collective} and robotics control systems \cite{brooks1989robot, floreano1996evolution, kodjabachian1998evolution}.
% complexification
An advanced \gls{tweann} technique is \gls{neat} \cite{stanley2002evolving}.
\gls{neat} introduces the concept of \textit{complexification} of controllers; an \gls{ann} is evolved starting from a simple topology by adding new neurons and new synaptic connections, besides evolving the weights, by means of evolutionary operators.
In~\cite{stanley2004competitive}, \citeauthor{stanley2004competitive} show that through the complexification of agent controllers in a competitive co-evolutionary setting, the controller's added complexity can be used through the generation of more advanced strategies as complexity increases.
\gls{neat} allows for the addition of connections and or nodes to a \gls{nn} while maintaining learned behaviours by keeping the encoded information in the resized \gls{nn} very close to its previous state, resolving the problem of \textit{competing conventions} with genetic markers as explained in \cite{floreano2008neuroevolution, stanley2002evolving}.

\subsection{Homogeneous \& Heterogeneous Controllers}
Assigning controllers to a group of agents can be done in two different modes: \textit{homogeneous} and \textit{heterogeneous}.
% explain homogeneity
In homogeneous mode, the agents are assigned the same high-level controller.
This allows redundancy of the robots' behaviour so that if one fails, the rest of the team can still complete the task.
\citeauthor{balch1998behavioral} in \cite{balch1998behavioral} shows that certain tasks, such as foraging, were solved more easily by a team of homogeneous robots.
% explain heterogeneity
In heterogeneous mode instead, agents are allowed to co-evolve their own controllers and therefore each agent has its own control structure.
This approach allows the emergence of specialization within a team of robots, as detailed in \cite{balch1998behavioral}.
Thus it may be a great fit in domains such as soccer, where multiple roles are required.
\citeauthor{luke1998genetic} give a good exemplification of the different challenges in homogeneous and heterogeneous approaches in \cite{luke1998genetic}.
They developed a team of robots for the \textit{RoboCup97} with both approaches but only the homogeneous team was entered the competition.
The heterogeneous team had a much bigger search space to search for and one of the goals of the authors was to obtain the best possible team in a limited amount of time.
In \cite{potter2001heterogeneity}, the authors analysed the trade-off of homogeneity versus heterogeneity in robotics control systems by allowing teams to co-evolve their high-level controllers given different levels of difficulty of the task.
The hypothesis was ``simply increasing the difficulty of a task is not enough to induce a team of robots to create specialists''.
Task difficulty was varied by replacing one adversary's passive controller with an active variant supposedly proving that increased difficulty did not justify the use of heterogeneous controllers.
However, increased difficulty was never implemented structurally nor tested methodologically. 

\section{Model design}
\label{sec:model_design}
%This can be considered as an extension of~\cite{potter2001heterogeneity} because the task, as well as part of the model, are similar. 
In this section we detail our model which aims to simulate a herding task by employing robots with intelligent controllers.
% Herding environment + Task complexity
The herding task involves shepherd agents trying to push sheep agents into a corral, this is further detailed in Section~\ref{sec:herding_task_environment}.
%% Positioning system
%In particular, the positioning system used to control and direct movements of the agents, is described in Section~\ref{sec:positioning_system}. 
% NN_design
Controllers of both shepherds and sheep are modelled differently in a high level manner using NNs.
The NN designs are explained in Section~\ref{sec:NN_design} and how the evolution process is detailed in Section~\ref{sec:controllers_evolution}.
% obstacle_avoidance + NN_output_interpretation
Agents have a simple obstacle avoidance system that allows them to interact with each other, bump into walls and makes the shepherd capable of herding the sheep.
Furthermore, in order to move agents using the output of the NN controllers, the NN output has to be translated into Cartesian coordinates.
Both steps are specified in Section~\ref{sec:agents_design}.

\subsection{Herding task and environment}
\label{sec:herding_task_environment}
% herding task + environment
The task domain is herding (a sub-domain of the more general pursuit evasion task).
%TODO do we need some source for this evasion task?
Our objective is to simulate shepherd agents trying to push sheep agents into a corral. 
The environment consists of a $l \times l$ squared pasture with fences on the top and bottom.
The corral is positioned on the right side, and the pasture is open on the left side for the sheep to escape.
% Task complexity
We modulate the task complexity by controlling the number of agents of each type that take part in the task, respectively $D$ for the shepherds (or dogs) and $S$ for the sheep.
Thus, we deploy it as the shepherd to sheep ratio, defined as $\phi = D / S$, where an increased ratio implies a more complex task for the shepherds.

% Positioning system
We use an agent centred polar coordinate system where an agent's position is relative to a second agent of the same type (i.e., shepherd or sheep).
The coordinate system's polar axis passes through the center of the corral and the second agent's position. 
Within this system, a coordinate pair is defined as $\mathbf{p} = (r, b)$, where $r$ is the distance to the second agent (range) and $b$ is the angle from between the two agents, relative to the polar axis (bearing).
In order to define the position of a group of sheep, we take into account the center of mass $\mathbf{gc}$, which is equal to the position of the sheep when only one sheep is present.
% explain how we calculate the gc
The center the sheep group is calculated like the center of mass of a particle system, as following:
\begin{equation} \label{eq:gc}
\mathbf{gc} = \frac{1}{S} \sum_{i=1}^{S}{\mathbf{x_i}}
\end{equation}
where $\mathbf{x_i}$ is the $i-th$ sheep's position in Cartesian coordinates.
The overall task environment described here is depicted in Figure~\ref{fig:task_env}. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/herding_environment.png}
	\caption{Herding task environment and detail of the positioning coordinates for a group of sheep.}
	\label{fig:task_env}
\end{figure}


\subsection{Neural Networks design}
\label{sec:NN_design}
The controllers for the agents are feedforward neural networks~\cite{bebis1994feed} with one hidden layer.
% Inputs
The inputs for the NNs are a fixed \textit{bias} of $1$ and one or more instances of \textit{coordinate pairs} (defined in Section~\ref{sec:herding_task_environment}).
In order to support scenarios with diverse numbers of agents, we design two different NNs: the \textit{single-pair} and the \textit{multi-pair} networks. 
% Single-pair NN
In the case of a \textit{single-pair} network, an agent can only see one other agent so the network consists of two input nodes, one for each item of a \textit{coordinate pair} and its hidden layer has three nodes. 
This network is showed in Figure~\ref{fig:single_pair_topology}.
The input nodes are labelled \textit{opponent} because the input given to the network represents coordinates of an opposing agent.
% Multi-pair NN
Alternatively, to enable an agent to cooperate with its allies, we assign to it a \textit{multi-pair} neural network, with four input nodes for the coordinate, and five nodes in its hidden layer.
This NN design is shown in Figure~\ref{fig:multi_pair_topology}.
The input nodes are labelled \textit{opponent} and \textit{ally} because the inputs given to the network represent coordinates of one opponent and one ally.

Moreover, for every NNs the activation function is a sigmoid function $S(t) = (1 + e^{-t})^{-1}$, centred at $0$. 
The output of the network is a polar \textit{coordinates pair}, namely \textit{target position}, that represents the
location towards which the agent will try to move to in the next time step.
Finally, the output of the NN has a range from $(0, 1)$, so in order to convert this into the used positioning system it is translated into a range of $[0, l]$ for target ranges and $[-\pi, \pi]$ for target bearings. 
 
\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\hsize]{imgs/nn-design_single.png}
	\caption{Single-pair neural network.}
	\label{fig:single_pair_topology}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/nn-design_multi.png}
	\caption{Multi-pair neural network.}
	\label{fig:multi_pair_topology}
\end{figure}

\vspace{0.5em}
% Shepherds controllers
\subsubsection{Shepherds controllers}
Shepherds evolve \textit{cooperative} behaviours among themselves to successfully herd sheep.
Therefore, the \textit{competitive} behaviour is against the sheep, who temps to escape. 
In order to pursue cooperation, a shepherd needs information about the other shepherds around. 
However, in order to keep the network complexity low we only provide the controller with information for the closest shepherd. 
Similarly, the competition creates the need for the shepherd to have information about the sheep.
Thus, the inputs for a shepherd controller are: 

\begin{enumerate}
	\item \textit{closestSheep\_r}: Distance from this shepherd to the closest sheep.
	\item \textit{closestSheep\_b}: Bearing between this shepherd and the closest sheep. 
	\item \textit{closestShepherd\_r}: Distance from this shepherd to the closest other shepherd.
	\item \textit{closestShepherd\_b}: Bearing between this shepherd and the closest other shepherd.
\end{enumerate}

We highlight that the third and fourth inputs are not taken into account in scenarios where there is only one shepherd. 

\vspace{0.5em}
% Sheep controllers
\subsubsection{Sheep controllers}
In case of the sheep, competitive and cooperative behaviours are pursued using the same logic as the shepherd's when defining the NN inputs. 
This time, in order to avoid the shepherd and be able to escape, sheep have information about the closest shepherd. 
Yet, they have a strong preference to stay in a group and so need information about the closest sheep around them in order to pursue this goal. 
Thus, the inputs for a sheep's controller are:

\begin{enumerate}
	\item \textit{closestShepherd\_r}: Distance from this sheep to the closest shepherd.
	\item \textit{closestShepherd\_b}: Bearing between this sheep and the closest shepherd.
	\item \textit{closestSheep\_r}: Distance from this sheep to the closest other sheep.
	\item \textit{closestSheep\_b}: Bearing between this sheep and the closest other sheep.
\end{enumerate}

Once again, we point out the third and fourth inputs are not taken into account in scenarios where there is only one sheep. 

\subsection{Evolution of controllers}
\label{sec:controllers_evolution}
The algorithm used to evolve the controllers follows the framework of evolution strategies (ES) \cite{back1993overview}. 
We use the ($\mu + \lambda$) strategy, with $\mu = 10$ and $\lambda = 100$~\cite{eiben2003introduction}. 
An ($\mu + \lambda$) ES generates $\lambda$ children from a population of $\mu$ individuals by mutating them; therefore no crossover operator is used.
The $\mu + \lambda$ children are then evaluated and the best $\mu$ individuals among them are selected for the next generation.
The genome is a real-valued vector representing the connection weights of the neural network
The genome can be of two sizes (depending on the scenario): $17$ for the \textit{simple-pair} network and $37$ for the \textit{multi-pair} network. 
Furthermore, each individual in a population is evaluated with the best individuals from the other populations, following an elitist approach.
Different fitness functions are created for each type of agent, we hereby explain each of them and motivate its design.

\vspace{0.5em}
\subsubsection{Shepherd fitness function}
In order to show the shepherd fitness function, we introduce here~\eqref{eq:gcDist}, the euclidean distance from the sheep center of group mass $gc$ (see Section~\ref{sec:herding_task_environment}) to the corral position $cr$.
Given $t$ as an incremental index of the simulation time steps, it is defined as:
% GROUP CENTER OF MASS DISTANCE
\begin{equation} \label{eq:gcDist}
gcd(t) = \sqrt{(cr_x - gc_x(t))^2 + (cr_y - gc_y(t))^2}
\end{equation}
This metric grows as the group of sheep distance itself from the corral in the attempt to escape.
Furthermore, at every time step a \textit{bonus} is rewarded for corralling a sheep or a \textit{penalty} is deducted for letting a sheep escape. 
Each of these rewards is regulated by the elapsed simulation time, meaning that a bonus/penalty is larger the earlier the rewarded event happens.
% SHEPHERD BONUS
\begin{equation} \label{eq:bonus}
bonus(t) = - l (T - t)
\end{equation}
% SHEPHERD PENALTY
\begin{equation} \label{eq:penalty}
penalty(t) = l (T - t)
\end{equation}
Where $T$ is the number of total steps (1500 in our experiments) and $t$ is the number of elapsed steps the moment the simulation is stopped.
Finally, the fitness for shepherds is defined as the cumulative distance from the sheep center to the corral position~\eqref{eq:gcDist} taking into account bonuses~\eqref{eq:bonus} and penalties~\eqref{eq:penalty}, over every simulation time step:
% SHEPHERD FITNESS
\begin{equation} \label{eq:shep_fitness}
f_{sheph} = \sum_{i=1}^{1500} gcd(i)	+ bonus(i) + penalty(i)
\end{equation}
In order to observe herding behaviour,~\eqref{eq:shep_fitness} has to be minimized.
Note that the fitness is the same among a group of shepherds, since all the components reflect on the group's performance. 
This design choice is motivated by the fact that shepherds must work together to achieve a common goal. 

\vspace{0.5em}
\subsubsection{Sheep fitness function}
The fitness for a sheep is determined by its own distance to the corral. 
% SHEEP DISTANCE
\begin{equation} \label{eq:sheep_dist}
sd(t) = \sqrt{(cr_x - sheep_x(t))^2 + (cr_y - sheep_y(t))^2}
\end{equation}
In scenarios involving more than one sheep, a group component is added to motivate sheep to stay together. 
This is the ratio $\phi$ of the group calculated as the distance from the furthest sheep $\alpha$ to the center of mass $gc$ in a specific time step. 
% SHEEP RATIO
\begin{equation} \label{eq:sheep_ratio}
\phi(t) = \sqrt{(\alpha_x(t) - gc_x(t))^2 + (\alpha_y - gc_y(t))^2}
\end{equation}
Similarly to the shepherds, bonuses and penalties are given when a sheep escapes or is corralled, accordingly:
% SHEEP BONUS
\begin{equation} \label{eq:sheep_bonus}
f_{sheep}(x) = f_{sheep}(x) + l (T - t)
\end{equation}
% SHEEP PENALTY
\begin{equation} \label{eq:sheep_pen}
f_{sheep}(x) = f_{sheep}(x) - l (T - t)
\end{equation}
Where $T$ is the number of total steps (1500 in our experiments) and $t$ is the number of elapsed steps when the simulation stopped.
Since larger distances but smaller ratios are desired, the fitness function is determined as the individual distance minus the group ratio, added over the simulation time steps. 
% SHEEP FITNESS
\begin{equation} \label{eq:sheep_fitness}
f_{sheep}(x) = \sum_{i=1}^{1500}(sd(i) - {RR} \phi(i))
\end{equation}
where $0 \leq RR \geq 1$ is a constant that controls the weight of the sheep-radius component on the sheep's fitness score.


\subsection{Agents}
\label{sec:agents_design}
% Obstacle avoidance
The output of the NN produce a target direction for the agents to move towards.
However, both types of agents have an obstacle avoidance mechanism that may override the network's output, hindering an agent's movement when necessary.
To achieve this each agent is provided with a \textit{radius} which allows to push other agents with a smaller radius.
Obstacles entering this radius hinder the agent from moving in this direction and will reposition the agent preventing overlap between object and radius.
We assign a greater radius to the shepherd then to the sheep, by doing so we allow the shepherd to push, and thus herd, the sheep towards the corral.

% Interpreting the Neural Network output
Since the output of the network is represented as polar coordinates centred with the polar axis passing through the nearest opponent, they are translated into Cartesian coordinates within the pasture to calculate the agents target position.
% TODO: explain the transformation
%TODO: Others properites: like speed....
All agents have the same maximum speed and mass, so their simulated physical characteristics are the same.
Both maximum speed and mass have a value of $1$ simulated units.



\section{Experimental results}
\label{sec:experiment}
In order to answer the research questions listed in {Section~\ref{sec:researchQuestions}} and test its corresponding hypothesis in {Section~\ref{sec:hypothesis}}, we execute the co-evolutionary algorithm in the different scenarios for $100$ generations. 
We run the entire evolutionary process for $40$ times and perform statistical analysis to get $95\%$ confidence intervals.

\subsection{Implementation}
\label{sec:implementation}
%TODO: the implementation is the description of the instance of our model used to run the experiments, this means that all parameters should be defined (name+meaning) in the model section and instanciated in the implementation.  The impl. is not much about the code/classes etc unless we came up with a novel algortihm....
The project is coded in Java and has a GUI to launch the different experiments, replay the best individuals for each generation and plot statistics.
The evolutionary algorithm is implemented through the use of \textit{ECJ} \cite{luke2006ecj}: an easy to use evolutionary computation research framework with out-of-the-box algorithms and tools that enabled us to implement our co-evolutionary ES.
To realise the simulation environment and its agents, we use \textit{MASON} \cite{luke2005mason}, developed at the George Mason University's ECLab Evolutionary Computation Laboratory as a sister project of ECJ.
Moreover we use \textit{neuroph} \footnote{http://neuroph.sourceforge.net/} to create and handle the neural networks.

Because with a co-evolutionary setting ECJ can only do maximization problems, the shepherd fitness score is negated in the implementation, that is:
$$ f_{sheph}(x) = -f_{sheph}(x) $$
In our experiments we give a value of $0.8$ to the constant $RR$ of equation \eqref{eq:sheep_fitness}, reducing the weight given to the flocking behaviour produced by \eqref{eq:sheep_ratio}.

Like in \cite{potter2001heterogeneity}, a simulation consists of 2.5 simulated minutes and the agents refresh their target position every 10Hz.
This is equivalent to $1500$ simulation steps in which the agents refresh their target every step.
To do so, an agent firstly acquires its inputs and then propagates them through its neural network computing a new target position that the simulation environment will translate in forces to be applied to the agent's virtual body.



\subsubsection{Environment and Agents}
The size of the pasture is fixed across all the experiments at $l = 37$ simulated units.
As already stated in \ref{sec:agents_design}, the shepherd is equipped with a greater radius than the sheep's.
This is to allow them to effectively herd the sheep by rimming and pushing it towards the corral.
Therefore we assign a radius of $3$ and $2$ simulation units to the shepherd and to the sheep respectively.
The pasture is closed on the top and bottom sides, with the corral positioned on the right side, opposite to an open side that enables the sheep to escape.
The initial positions of the agents inside the pasture are shown in Figure \ref{fig:simulation_screenshot} for a full \textit{three vs. three} experiment.
The initial locations values used in the experiments are:
\begin{align}
sheph_x &= \frac{l}{2} - 6 \\
sheph_y(i) &= \frac{l}{2} + \begin{cases} 0 & \text{if } i=1 \\ -6 & \text{if } i=2 \\ +6 & \text{if } i=3 \end{cases} \\
sheep_x &= \frac{l}{2} + 6 \\
sheep_y(i) &= \frac{l}{2} + \begin{cases} 0 & \text{if } i=1 \\ -4 & \text{if } i=2 \\ +4 & \text{if } i=3 \end{cases}
\end{align}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/pasture.png}
	\caption{Screenshot of the simulation with the shepherds (blue ones) and the sheep (gray ones), almost at the starting locations.}
	\label{fig:simulation_screenshot}
\end{figure}


\subsubsection{Evolution}
In order to calculate the fitness for an individual, all controllers are evaluated through 10 trials of the task and the average is taken as fitness.
Every trial runs for a maximum of $1500$ time steps. 
In cases where there is more than one sheep, a complex network is assigned to all sheep. 
The simulation ends before the time elapses as soon as one sheep is corralled or escapes. 
The reason for leaving one sheep left in the pasture when ending the simulation is that the number of inputs for the sheep controllers is fixed before the beginning of a trial, and having no other sheep left would lead to null inputs and misbehaviour. 
In cases where there is only one sheep, a simple controller is assigned. 
Thus, the sheep must either be corralled or has to escape in order for the simulation to stop before the time expires.

In homogeneous set-ups we evolve one controller per type of agent, meaning we have two subpopulations, one for shepherds and one for sheep, co-evolving. 
However, to create heterogeneity a population per agent is created. 
For example, in a scenario with two shepherds and one sheep, there is a total of three subpopulations, two of them cooperating among each other and competing with the third one.  



\subsection{Performance details}
\label{sec:experiments_performances}
In this section we present the results of the experiments run using the implementation detailed in Section~\ref{sec:implementation}.
% Homo vs Etero experiment
\vspace{0.5em}
\subsubsection{Homo vs Hetero}
We first consider two experiments that relate to $H_1$, here the IV is the controller type (homo or hetero).
Note that the first and the second run involves respectively 2 and 3  shepherds.
Figure~\ref{fig:2v1_homo_vs_hetero} reports the former case, while Figure~\ref{fig:3v1_homo_vs_hetero} the latter.
In order to provide a statistical point of view, we perform \textit{t}-test on the means of the homogeneous and heterogeneous trials, which produced a \textit{p}-value $\ll0.5$ for both cases.
Thus, supported by the significant difference between the homogeneous and heterogeneous cases, we reject the null hyptoesis (see Section~\ref{sec:hypothesis}).

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\hsize]{imgs/homo2v1-hetero2v1-bestSoFar.pdf}
	\caption{Best individuals fitness in scenario with two shepherds and one sheep. Both homogeneous and heterogeneous settings are shown}
	\label{fig:2v1_homo_vs_hetero}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=1\hsize]{imgs/homo3v1-hetero3v1-bestSoFar.pdf}
	\caption{Best individuals fitness in scenario with three shepherds and one sheep. Both homogeneous and heterogeneous settings are shown}
	\label{fig:3v1_homo_vs_hetero}
\end{figure}


%% Need for heterogeneous controllers
%\vspace{0.5em}
%\subsubsection{Need for heterogeneousity}
%In order to test $H_2$, we compare different scenarios with different number of shepherds corralling one sheep:
%\begin{itemize}
%	\item 1 shepherd vs 1 sheep	
%	\item 2 homogeneous shepherds vs 1 sheep
%	\item 3 homogeneous shepherds vs 1 sheep
%	\item 2 heterogeneous shepherds vs 1 sheep
%	\item 3 heterogeneous shepherds vs 1 sheep
%	
%\end{itemize}

%% Task complexity: more sheep!
%\vspace{0.5em}
%\subsubsection{Task complexity: sheep number}
%Finally, $H_3$ is approached by comparing scenarios with a fixed number of shepherds, in this case three, and different number of sheep. 
%\begin{itemize}
%	\item 3 heterogeneous shepherds vs 1 sheep
%	\item 3 heterogeneous shepherds vs 2 homogeneous sheep
%	\item 3 heterogeneous shepherds vs 3 homogeneous sheep
%\end{itemize}
%The second and third round of experiments regulate the task complexity by having different sheep to shepherd ratios. 
%\begin{itemize}
%	\item one shepherd one sheep = 1 ratio
%	\item two shepherds one sheep = 0.5 ratio
%	\item three shepherds one sheep = 0.33 ratio
%	
%	\item three shepherd one sheep = 0.33 ratio
%	\item three shepherd two sheep = 0.66 ratio
%	\item three shepherd three sheep = 1
%\end{itemize}




%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_1v1-hetero_2v1-hetero_3v1-corralledRatio-bar.jpeg}
%	\caption{Bar chart for corralled cases in heterogeneous setting. Shows mean, best and worse for scenarios with one, two and three shepherds herding one sheep}
%	\label{fig:corralled_oneSheep}
%\end{figure}
%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_1v1-hetero_2v1-hetero_3v1-escapedRatio-bar.jpeg}
%	\caption{Bar chart for escaped cases in heterogeneous setting. Shows mean, best and worse for scenarios with one, two and three shepherds herding one sheep}
%	\label{fig:escaped_oneSheep}
%\end{figure}
%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_3v1-hetero_3v2-hetero_3v3-corralledRatio-bar.jpeg}
%	\caption{Bar chart for corralled cases in heterogeneous setting. Shows mean, best and worse for scenarios with three shepherds herding one, two and three sheep}
%	\label{fig:corralled_threeShepherd}
%\end{figure}
%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_3v1-hetero_3v2-hetero_3v3-escapedRatio-bar.jpeg}
%	\caption{Bar chart for escaped cases in heterogeneous setting. Shows mean, best and worse for scenarios with three shepherds herding one, two and three sheep}
%	\label{fig:escaped_threeShepherd}
%\end{figure}



\section{Conclusion}
\label{sec:conclusion}
The conclusion goes here.



% \bibliographystyle{abbrv}
% \bibliography{bibliography}
\printbibliography



\end{document}

