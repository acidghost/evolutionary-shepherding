\documentclass[conference]{IEEEtran}

\ifCLASSINFOpdf

\else

\fi


\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{mathtools}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
 
\title{Competitive co-evolution in robots: \\ heterogeneity vs homogeneity}



\author{\IEEEauthorblockN{Selene Baez Santamaria, Andrea Jemmett, Tommie Kerstens, Enrico Rotundo}
\IEEEauthorblockA{
Vrije Universiteit Amsterdam \\
Amsterdam, Netherlands}}



\maketitle


\begin{abstract}
In the context of robotics, intelligent behaviours are often achieved using neural networks as controllers evolved using  an evolutionary algorithm.
In the case of multiple individuals within a species, controllers can be either homogeneous or heterogeneous.
In this paper, we use competitive co-evolution of homogeneous and heterogeneous controllers in order to investigate its effects on the emergence of specialisation behaviour regarding a herding task.

TODO: add what we have discovered!!!!!!!
% TODO: add what we have discovered
\end{abstract}


\IEEEpeerreviewmaketitle


\section{Introduction}
% Evolutionary Algorithms
Evolutionary algorithms (EA) are biology inspired algorithms that, going through multiple steps (e.g., generation, procreation, etc.), are able to evolve entities over time.
Thus, the entities subject to the evolution are referred to as individuals,
%and the EA acts as the digital environment these individuals are born, live, procreate and die in.
and the evolution is usually controlled such that next generations improve along runs.
In the field of robotics, EAs can be used to evolve the behavioural controller of robots, these controllers are evolved as individuals in an EA.
% Neural Networks
A Neural Network (NN) is a function estimator that can be used as a controller and its design is natural inspired by the biological nervous system.
In order to employ a NN as a controller, inputs usually come from sensors making observations of the environment, while the weights are evolved by an EA.
The complete evolutionary process can be run in a simulation which exploits the computer's computational power in order to evaluate many individuals in a reasonable time frame. 
In the field of robotics both EAs and NNs are employed to evolve intelligent behaviours that can pursue one or more given goals.

% Solvable tasks
Tasks composition and complexity can vary based on specific scenarios, in general it is the subject of many studies aiming to solve different tasks.
For instance, tasks can be relatively small (e.g., moving objects) or more based on collaboration between a number of individuals.
Research investigates collective behaviour in order to asses to which extent collaboration between individuals is feasible.  

% Our task/paper
In this paper, we consider competitive co-evolution within a herding task which consists of a number of shepherds that herd a sheep into a corral.
We evolve NN controllers and assign them to the agents, the latter step can be done with a homogeneous or heterogeneous approach.
While the former employs the same controller instance for each agent,
in the latter each agent gets its own instance of a controller, which is separately evolved by an EA.
Moreover, the task complexity can be increased by varying or introducing new agents like adding a fox.

In this paper we employ the aforementioned components within a simulated herding task.
We recap our objectives in the following list:

\begin{itemize}
	\item To compare homogeneity versus heterogeneity.
	\item To estimate the effect on homo versus heterogeneity of increasingly difficult task.
 	\item To develop controlled experiments through software simulations, using ad hoc libraries.
	\item To collect comprehensive results data.
\end{itemize}
 
\subsection{Research questions}
\label{sec:researchQuestions}
In the herding task, shepherds and sheep have opposing goals.
While the former tries to herd sheep into a corral, the latter tries to escape through the left side of the pasture. 
Species can be competitively co-evolved in a race to evolve strategies to accomplish opposing goals. 
Furthermore, the task complexity can be influenced by varying different parameters such as the number of present agents per each type or their relative movement speeds. 
Another type of dimension used to scale the difficulty is the type of controllers used,
Instances of different controller types can be either \textit{static} or \textit{intelligent}.
A \textit{static} controller is simply a predefined set of rules that implements a specific behaviour.
Although an \textit{intelligent} controller is more complex due to its ability to adept itself over time.
In this paper both the sheep and the shepherds have an \textit{intelligent} controller.
The intelligence of the controller is based on the assumption that the NN is evolved, and thus, the controller has the possibility to adapt to its environment through an evolutionary process. 
This process, in which many strategies are simulated and evaluated, is comparable to a learning process and enables adaptivity. 
Assuming an intelligent sheep we state the following research questions:

\begin{enumerate}
	\item How do homogeneous and heterogeneous shepherd controllers compare in a competitive co-evolved herding task?
	\item How does increasing the number of shepherds increase the need for heterogeneous controllers?
	\item How does increasing task complexity (by adding more sheep) affect the effectiveness of herding?
\end{enumerate}

\subsection{Hypothesis}
\label{sec:hypothesis}
The following hypothesis are in one to one relationship with the aforementioned research questions:

\begin{enumerate}
	\item Shepherds' fitness in the heterogeneous case is overall higher than in the homogeneous case.
	\item The number of shepherds herding one sheep is directly related to their fitness in heterogeneous cases, such that fitness increases as the number of shepherds increases.	
	\item Increasing the number of sheep herd by a fixed number of shepherds decreases the number of corralled sheep.
\end{enumerate}
$H_0$, namely the null hypothesis, is ``Shepherdsâ€™ fitness in the heterogeneous case is equivalent to the one of the homogeneous''.
%TODO: add null hyptoesis for H_2 and H_3

\subsection{Contributions}
In this paper we introduce our proposed model for running a herding task in a competitive co-evoulution framework. 
We have built our model and run a thorough set of simulations in order to test the hypothesis detailed in Section~\ref{sec:hypothesis}. 
In what follows, we list the main contributions of this paper to the state-of-the-art:
\begin{itemize}
	\item BLA
	\item PIZZA
	\item PASTA
	\item NESPRESSO....what else?
\end{itemize}

This work sheds a tiny light in the topic of competitive co-evoultion by showing to which extent it is feasible in a herding task accomplished by robots.

\subsection{Organization}
%TODO: finish this!
The rest of this paper is organized as follows. 
In Section X, we revise the state-of-the-art related to our research topic. 
In Section Y, we present our model, describing its different components. 
We evaluate the performance of our solution in Section Z. 
Finally, in Section M we draw some conclusions and point out ways to further extend this work.

\section{Literature review}
In this section, we survey the main researches in related work, considering different the following topics: \textit{co-evolution}, \textit{competitive co-evolution}, \textit{evolving NNs} and \textit{homogeneity \& heterogeneity in NNs}.
 
\subsection{Co-evolution}
Co-evolution in its foundation is a natural phenomena.
It describes how the basic principles of evolution are propagated through a dynamic process in which species not only evolve due to the selection pressure produced by an environment, but also due to the selection pressure produced as a by-product of other species evolving within that same environment.
The effects of co-evoultion in butterflies and plants have been studied as early as 1964 in ~\cite{ehrlich1964butterflies}.
Furthermore, the authors of ~\cite{janzen1980coevolution} define co-evolution as ``an evolutionary change in a trait of the individuals in one population in response to a trait of the individuals of a second population''. 
%In 1980 Janzen's \cite{janzen1980coevolution} formalised a clear definition for coevolution:
%`` 'Coevolution' may be usefully defined as an evolutionary change in a trait of the individuals in one population in response to a trait of the individuals of a second population, followed by an evolutionary response by the second populations to the change in the first.''


\subsection{Competitive Co-evolution}
In extension to the broader co-evolution, competitive co-evolution has, as its name suggest, a focus towards competitive elements creating selection pressure.
Dawkins and Krebs describe in~\cite{dawkins1979arms} the dynamics and terminology for competitive coevolution by providing examples of manifestations of competitive coevolution in natural systems. 
The paper captures the pure essential of competitive coevolution giving the following description: ``An adaptation in one lineage (e.g. predators) may change the selection pressure on another lineage (e.g. prey), giving rise to a counter-adaptation. If this occurs reciprocally, an unstable runaway escalation or 'arms race' may result''.

\subsection{Evolving NNs}
The weights of a NN can be evolved when possible configurations of these weights are subjected to selection pressure.
Using this technique, strategies to reach the goals the controlled agent is tempting to achieve become encoded in the ANN.
%get some paper showing simple evolution of NNs
In~\cite{stanley2004competitive}, the authors show that through the complexification of agent controllers in a competitive co-evolutionary setting, the controller's added complexity can be utilized through the generation of more advanced strategies as complexity increases. 
Complexification of the controllers was managed by increasing the size of the ANN gradually during the evolution run.
Resizing the network was achieved using NeuroEvolution of Augmenting Topologies (NEAT).
NEAT allows for the addition of connections and or nodes to a NN while maintaining learned behaviours by keeping the encoded information in the resized NN very close to its previous state.

\subsection{Homogeneity \& Heterogeneity in NNs}
\cite{potter2001heterogeneity} performed a study to a tradeoff of homogeneity versus heterogeneity in the control systems of robots by allowing teams to coevolve their high-level controllers given different levels of difficulty of the task.
The hypothesis was ``simply increasing the difficulty of a task is not enough to induce a team of robots to create specialists''.
Task difficulty was varied by replacing one adversary's passive controller with an active variant supposedly proving that increased difficulty did not justify the use of heterogeneous controllers.
However, increased difficulty was never implemented structurally nor tested methodologically. 

\section{Model design}
%This can be considered as an extension of~\cite{potter2001heterogeneity} because the task, as well as part of the model, are similar. 
In this section we detail our model which aims to simulate a herding task by employing robots with intelligent controllers.
% Herding environment + Task complexity
The herding task involves shepherd agents trying to push sheep agents into a corral, this is further detailed in Section~\ref{sec:herding_task_environment}.
%% Positioning system
%In particular, the positioning system used to control and direct movements of the agents, is described in Section~\ref{sec:positioning_system}. 
% NN_design
Controllers of both shepherds and sheep are modelled differently in a high level manner using NNs.
The NN designs are explained in Section~\ref{sec:NN_design} and how the evolution process is detailed in Section~\ref{sec:controllers_evolution}.
% obstacle_avoidance + NN_output_interpretation
Agents have a simple obstacle avoidance system that allows them to interact with each other, bump into walls and makes the shepherd capable of herding the sheep.
Furthermore, in order to move agents using the output of the NN controllers, the NN output has to be translated into Cartesian coordinates.
Both steps are specified in Section~\ref{sec:agents_design}.

\subsection{Herding task and environment}
\label{sec:herding_task_environment}
% herding task + environment
The task domain is herding (a sub-domain of the more general pursuit evasion task).
%TODO do we need some source for this evasion task?
Our objective is to simulate shepherd agents trying to push sheep agents into a corral. 
The environment consists of a $l \times l$ squared pasture with fences on the top and bottom.
The corral is positioned on the right side, and the pasture is open on the left side for the sheep to escape.
% Task complexity
We modulate the task complexity by controlling the number of agents of each type that take part in the task, respectively $D$ for the shepherds (or dogs) and $S$ for the sheep.
Thus, we deploy it as the shepherd to sheep ratio, defined as $\phi = D / S$, where an increased ratio implies a more complex task for the shepherds.

% Positioning system
We use an agent centred polar coordinate system where an agent's position is relative to a second agent of the same type (i.e., shepherd or sheep).
The coordinate system's polar axis passes through the center of the corral and the second agent's position. 
Within this system, a coordinate pair is defined as $\mathbf{p} = (r, b)$, where $r$ is the distance to the second agent (range) and $b$ is the angle from between the two agents, relative to the polar axis (bearing).
In order to define the position of a group of sheep, we take into account the center of mass $\mathbf{gc}$, which is equal to the position of the sheep when only one sheep is present.
% explain how we calculate the gc
The center the sheep group is calculated like the center of mass of a particle system, as following:
\begin{equation} \label{eq:gc}
\mathbf{gc} = \frac{1}{S} \sum_{i=1}^{S}{\mathbf{x_i}}
\end{equation}
where $\mathbf{x_i}$ is the $i-th$ sheep's position in Cartesian coordinates.
The overall task environment described here is depicted in Figure~\ref{fig:task_env}. 

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/herding_environment.png}
	\caption{Herding task environment and detail of the positioning coordinates for a group of sheep.}
	\label{fig:task_env}
\end{figure}


\subsection{Neural Networks design}
\label{sec:NN_design}
The controllers for the agents are feedforward neural networks~\cite{bebis1994feed} with one hidden layer.
% Inputs
The inputs for the NNs are a fixed \textit{bias} of $1$ and one or more instances of \textit{coordinate pairs} (defined in Section~\ref{sec:herding_task_environment}).
In order to support scenarios with diverse numbers of agents, we design two different NNs: the \textit{single-pair} and the \textit{multi-pair} networks. 
% Single-pair NN
In the case of a \textit{single-pair} network, an agent can only see one other agent so the network consists of two input nodes, one for each item of a \textit{coordinate pair} and its hidden layer has three nodes. 
This network is showed in Figure~\ref{fig:single_pair_topology}.
The input nodes are labelled \textit{opponent} because the input given to the network represents coordinates of an opposing agent.
% Multi-pair NN
Alternatively, to enable an agent to cooperate with its allies, we assign to it a \textit{multi-pair} neural network, with four input nodes for the coordinate, and five nodes in its hidden layer.
This NN design is shown in Figure~\ref{fig:multi_pair_topology}.
The input nodes are labelled \textit{opponent} and \textit{ally} because the inputs given to the network represent coordinates of one opponent and one ally.

Moreover, for every NNs the activation function is a sigmoid function $S(t) = (1 + e^{-t})^{-1}$, centred at $0$. 
The output of the network is a polar \textit{coordinates pair}, namely \textit{target position}, that represents the
location towards which the agent will try to move to in the next time step.
Finally, the output of the NN has a range from $(0, 1)$, so in order to convert this into the used positioning system it is translated into a range of $[0, l]$ for target ranges and $[-\pi, \pi]$ for target bearings. 
 
\begin{figure}[t]
	\centering
	\includegraphics[width=0.5\hsize]{imgs/nn-design_single.png}
	\caption{Single-pair neural network.}
	\label{fig:single_pair_topology}
\end{figure}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/nn-design_multi.png}
	\caption{Multi-pair neural network.}
	\label{fig:multi_pair_topology}
\end{figure}

\vspace{0.5em}
% Shepherds controllers
\subsubsection{Shepherds controllers}
Shepherds evolve \textit{cooperative} behaviours among themselves to successfully herd sheep.
Therefore, the \textit{competitive} behaviour is against the sheep, who temps to escape. 
In order to pursue cooperation, a shepherd needs information about the other shepherds around. 
However, in order to keep the network complexity low we only provide the controller with information for the closest shepherd. 
Similarly, the competition creates the need for the shepherd to have information about the sheep.
Thus, the inputs for a shepherd controller are: 

\begin{enumerate}
	\item \textit{closestSheep\_r}: Distance from this shepherd to the closest sheep.
	\item \textit{closestSheep\_b}: Bearing between this shepherd and the closest sheep. 
	\item \textit{closestShepherd\_r}: Distance from this shepherd to the closest other shepherd.
	\item \textit{closestShepherd\_b}: Bearing between this shepherd and the closest other shepherd.
\end{enumerate}

We highlight that the third and fourth inputs are not taken into account in scenarios where there is only one shepherd. 

\vspace{0.5em}
% Sheep controllers
\subsubsection{Sheep controllers}
In case of the sheep, competitive and cooperative behaviours are pursued using the same logic as the shepherd's when defining the NN inputs. 
This time, in order to avoid the shepherd and be able to escape, sheep have information about the closest shepherd. 
Yet, they have a strong preference to stay in a group and so need information about the closest sheep around them in order to pursue this goal. 
Thus, the inputs for a sheep's controller are:

\begin{enumerate}
	\item \textit{closestShepherd\_r}: Distance from this sheep to the closest shepherd.
	\item \textit{closestShepherd\_b}: Bearing between this sheep and the closest shepherd.
	\item \textit{closestSheep\_r}: Distance from this sheep to the closest other sheep.
	\item \textit{closestSheep\_b}: Bearing between this sheep and the closest other sheep.
\end{enumerate}

Once again, we point out the third and fourth inputs are not taken into account in scenarios where there is only one sheep. 

\subsection{Evolution of controllers}
\label{sec:controllers_evolution}
The algorithm used to evolve the controllers follows the framework of evolution strategies (ES) \cite{back1993overview}. 
We use the ($\mu + \lambda$) strategy, with $\mu = 10$ and $\lambda = 100$~\cite{eiben2003introduction}. 
An ($\mu + \lambda$) ES generates $\lambda$ children from a population of $\mu$ individuals by mutating them; therefore no crossover operator is used.
The $\mu + \lambda$ children are then evaluated and the best $\mu$ individuals among them are selected for the next generation.
The genome is a real-valued vector representing the connection weights of the neural network
The genome can be of two sizes (depending on the scenario): $17$ for the \textit{simple-pair} network and $37$ for the \textit{multi-pair} network. 
Furthermore, each individual in a population is evaluated with the best individuals from the other populations, following an elitist approach.
Different fitness functions are created for each type of agent, we hereby explain each of them and motivate its design.

\vspace{0.5em}
\subsubsection{Shepherd fitness function}
In order to show the shepherd fitness function, we introduce here~\eqref{eq:gcDist}, the euclidean distance from the sheep center of group mass $gc$ (see Section~\ref{sec:herding_task_environment}) to the corral position $cr$.
Given $t$ as an incremental index of the simulation time steps, it is defined as:
% GROUP CENTER OF MASS DISTANCE
\begin{equation} \label{eq:gcDist}
gcd(t) = \sqrt{(cr_x - gc_x(t))^2 + (cr_y - gc_y(t))^2}
\end{equation}
This metric grows as the group of sheep distance itself from the corral in the attempt to escape.
Furthermore, at every time step a \textit{bonus} is rewarded for corralling a sheep or a \textit{penalty} is deducted for letting a sheep escape. 
Each of these rewards is regulated by the elapsed simulation time, meaning that a bonus/penalty is larger the earlier the rewarded event happens.
% SHEPHERD BONUS
\begin{equation} \label{eq:bonus}
bonus(t) = - l (T - t)
\end{equation}
% SHEPHERD PENALTY
\begin{equation} \label{eq:penalty}
penalty(t) = l (T - t)
\end{equation}
Where $T$ is the number of total steps (1500 in our experiments) and $t$ is the number of elapsed steps the moment the simulation is stopped.
Finally, the fitness for shepherds is defined as the cumulative distance from the sheep center to the corral position~\eqref{eq:gcDist} taking into account bonuses~\eqref{eq:bonus} and penalties~\eqref{eq:penalty}, over every simulation time step:
% SHEPHERD FITNESS
\begin{equation} \label{eq:shep_fitness}
f_{sheph} = \sum_{i=1}^{1500} gcd(i)	+ bonus(i) + penalty(i)
\end{equation}
In order to observe herding behaviour,~\eqref{eq:shep_fitness} has to be minimized.
Note that the fitness is the same among a group of shepherds, since all the components reflect on the group's performance. 
This design choice is motivated by the fact that shepherds must work together to achieve a common goal. 

\vspace{0.5em}
\subsubsection{Sheep fitness function}
The fitness for a sheep is determined by its own distance to the corral. 
% SHEEP DISTANCE
\begin{equation} \label{eq:sheep_dist}
sd(t) = \sqrt{(cr_x - sheep_x(t))^2 + (cr_y - sheep_y(t))^2}
\end{equation}
In scenarios involving more than one sheep, a group component is added to motivate sheep to stay together. 
This is the ratio $\phi$ of the group calculated as the distance from the furthest sheep $\alpha$ to the center of mass $gc$ in a specific time step. 
% SHEEP RATIO
\begin{equation} \label{eq:sheep_ratio}
\phi(t) = \sqrt{(\alpha_x(t) - gc_x(t))^2 + (\alpha_y - gc_y(t))^2}
\end{equation}
Similarly to the shepherds, bonuses and penalties are given when a sheep escapes or is corralled, accordingly:
% SHEEP BONUS
\begin{equation} \label{eq:sheep_bonus}
f_{sheep}(x) = f_{sheep}(x) + l (T - t)
\end{equation}
% SHEEP PENALTY
\begin{equation} \label{eq:sheep_pen}
f_{sheep}(x) = f_{sheep}(x) - l (T - t)
\end{equation}
Where $T$ is the number of total steps (1500 in our experiments) and $t$ is the number of elapsed steps when the simulation stopped.
Since larger distances but smaller ratios are desired, the fitness function is determined as the individual distance minus the group ratio, added over the simulation time steps. 
% SHEEP FITNESS
\begin{equation} \label{eq:sheep_fitness}
f_{sheep}(x) = \sum_{i=1}^{1500}(sd(i) - {RR} \phi(i))
\end{equation}
where $0 \leq RR \geq 1$ is a constant that controls the weight of the sheep-radius component on the sheep's fitness score.


\subsection{Agents}
\label{sec:agents_design}
% Obstacle avoidance
The output of the NN produce a target direction for the agents to move towards.
However, both types of agents have an obstacle avoidance mechanism that may override the network's output, hindering an agent's movement when necessary.
To achieve this each agent is provided with a \textit{radius} which allows to push other agents with a smaller radius.
Obstacles entering this radius hinder the agent from moving in this direction and will reposition the agent preventing overlap between object and radius.
We assign a greater radius to the shepherd then to the sheep, by doing so we allow the shepherd to push, and thus herd, the sheep towards the corral.

% Interpreting the Neural Network output
Since the output of the network is represented as polar coordinates centred with the polar axis passing through the nearest opponent, they are translated into Cartesian coordinates within the pasture to calculate the agents target position.
% TODO: explain the transformation
%TODO: Others properites: like speed....
All agents have the same maximum speed and mass, so their simulated physical characteristics are the same.
Both maximum speed and mass have a value of $1$ simulated units.



\section{Experimental results}
\label{sec:experiment}
In order to answer the research questions listed in {Section~\ref{sec:researchQuestions}} and test its corresponding hypothesis in {Section~\ref{sec:hypothesis}}, we execute the co-evolutionary algorithm in the different scenarios for $100$ generations. 
We run the entire evolutionary process for $40$ times and perform statistical analysis to get $95\%$ confidence intervals.

\subsection{Implementation}
\label{sec:implementation}
%TODO: the implementation is the description of the instance of our model used to run the experiments, this means that all parameters should be defined (name+meaning) in the model section and instanciated in the implementation.  The impl. is not much about the code/classes etc unless we came up with a novel algortihm....
The project is coded in Java and has a GUI to launch the different experiments, replay the best individuals for each generation and plot statistics.
The evolutionary algorithm is implemented through the use of \textit{ECJ} \cite{luke2006ecj}: an easy to use evolutionary computation research framework with out-of-the-box algorithms and tools that enabled us to implement our co-evolutionary ES.
To realise the simulation environment and its agents, we use \textit{MASON} \cite{luke2005mason}, developed at the George Mason University's ECLab Evolutionary Computation Laboratory as a sister project of ECJ.
Moreover we use \textit{neuroph} \footnote{http://neuroph.sourceforge.net/} to create and handle the neural networks.

Because with a co-evolutionary setting ECJ can only do maximization problems, the shepherd fitness score is negated in the implementation, that is:
$$ f_{sheph}(x) = -f_{sheph}(x) $$
In our experiments we give a value of $0.8$ to the constant $RR$ of equation \eqref{eq:sheep_fitness}, reducing the weight given to the flocking behaviour produced by \eqref{eq:sheep_ratio}.

Like in \cite{potter2001heterogeneity}, a simulation consists of 2.5 simulated minutes and the agents refresh their target position every 10Hz.
This is equivalent to $1500$ simulation steps in which the agents refresh their target every step.
To do so, an agent firstly acquires its inputs and then propagates them through its neural network computing a new target position that the simulation environment will translate in forces to be applied to the agent's virtual body.



\subsubsection{Environment and Agents}
The size of the pasture is fixed across all the experiments at $l = 37$ simulated units.
As already stated in \ref{sec:agents_design}, the shepherd is equipped with a greater radius than the sheep's.
This is to allow them to effectively herd the sheep by rimming and pushing it towards the corral.
Therefore we assign a radius of $3$ and $2$ simulation units to the shepherd and to the sheep respectively.
The pasture is closed on the top and bottom sides, with the corral positioned on the right side, opposite to an open side that enables the sheep to escape.
The initial positions of the agents inside the pasture are shown in Figure \ref{fig:simulation_screenshot} for a full \textit{three vs. three} experiment.
The initial locations values used in the experiments are:
\begin{align}
sheph_x &= \frac{l}{2} - 6 \\
sheph_y(i) &= \frac{l}{2} + \begin{cases} 0 & \text{if } i=1 \\ -6 & \text{if } i=2 \\ +6 & \text{if } i=3 \end{cases} \\
sheep_x &= \frac{l}{2} + 6 \\
sheep_y(i) &= \frac{l}{2} + \begin{cases} 0 & \text{if } i=1 \\ -4 & \text{if } i=2 \\ +4 & \text{if } i=3 \end{cases}
\end{align}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\hsize]{imgs/pasture.png}
	\caption{Screenshot of the simulation with the shepherds (blue ones) and the sheep (gray ones), almost at the starting locations.}
	\label{fig:simulation_screenshot}
\end{figure}


\subsubsection{Evolution}
In order to calculate the fitness for an individual, all controllers are evaluated through 10 trials of the task and the average is taken as fitness.
Every trial runs for a maximum of $1500$ time steps. 
In cases where there is more than one sheep, a complex network is assigned to all sheep. 
The simulation ends before the time elapses as soon as one sheep is corralled or escapes. 
The reason for leaving one sheep left in the pasture when ending the simulation is that the number of inputs for the sheep controllers is fixed before the beginning of a trial, and having no other sheep left would lead to null inputs and misbehaviour. 
In cases where there is only one sheep, a simple controller is assigned. 
Thus, the sheep must either be corralled or has to escape in order for the simulation to stop before the time expires.

In homogeneous set-ups we evolve one controller per type of agent, meaning we have two subpopulations, one for shepherds and one for sheep, co-evolving. 
However, to create heterogeneity a population per agent is created. 
For example, in a scenario with two shepherds and one sheep, there is a total of three subpopulations, two of them cooperating among each other and competing with the third one.  



\subsection{Performance details}
\label{sec:experiments_performances}
In this section we present the results of the experiments run using the implementation detailed in Section~\ref{sec:implementation}.
% Homo vs Etero experiment
\vspace{0.5em}
\subsubsection{Controllers comparison}
We first consider experiments that relate to $H_1$. To investigate the difference between homogeneous and heterogeneous controllers for the shepherd agents, we explore scenarios with fixed number of agents. 
\begin{itemize}
	\item 2 homogeneous shepherds vs 1 sheep
	\item 2 heterogeneous shepherds vs 1 sheep
	\item 3 homogeneous shepherds vs 1 sheep
	\item 3 heterogeneous shepherds vs 1 sheep
\end{itemize}

\begin{figure}[ht]
	\centering
	\includegraphics[width=3.3in]{imgs/homo2v1-hetero2v1-bestSoFar.jpeg}
	\caption{Best individuals fitness in scenario with two shepherds and one sheep. Both homogeneous and heterogeneous settings are shown}
	\label{fig:2v1_homo_vs_hetero}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=3.3in]{imgs/homo3v1-hetero3v1-bestSoFar.jpeg}
	\caption{Best individuals fitness in scenario with three shepherds and one sheep. Both homogeneous and heterogeneous settings are shown}
	\label{fig:3v1_homo_vs_hetero}
\end{figure}


% Need for heterogeneous controllers
\vspace{0.5em}
\subsubsection{Need for heterogeneousity: shepherds number}
In order to test $H_2$, we compare different scenarios with different number of shepherds corralling one sheep:
\begin{itemize}
	\item 1 shepherd vs 1 sheep	
	\item 2 homogeneous shepherds vs 1 sheep
	\item 3 homogeneous shepherds vs 1 sheep
	\item 2 heterogeneous shepherds vs 1 sheep
	\item 3 heterogeneous shepherds vs 1 sheep
	
\end{itemize}

% Task complexity: more sheep!
\vspace{0.5em}
\subsubsection{Task complexity: sheep number}
Finally, $H_3$ is approached by comparing scenarios with a fixed number of shepherds, in this case three, and different number of sheep. 
\begin{itemize}
	\item 3 heterogeneous shepherds vs 1 sheep
	\item 3 heterogeneous shepherds vs 2 homogeneous sheep
	\item 3 heterogeneous shepherds vs 3 homogeneous sheep
\end{itemize}
The second and third round of experiments regulate the task complexity by having different sheep to shepherd ratios. 
\begin{itemize}
	\item one shepherd one sheep = 1 ratio
	\item two shepherds one sheep = 0.5 ratio
	\item three shepherds one sheep = 0.33 ratio
	
	\item three shepherd one sheep = 0.33 ratio
	\item three shepherd two sheep = 0.66 ratio
	\item three shepherd three sheep = 1
\end{itemize}




%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_1v1-hetero_2v1-hetero_3v1-corralledRatio-bar.jpeg}
%	\caption{Bar chart for corralled cases in heterogeneous setting. Shows mean, best and worse for scenarios with one, two and three shepherds herding one sheep}
%	\label{fig:corralled_oneSheep}
%\end{figure}

%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_1v1-hetero_2v1-hetero_3v1-escapedRatio-bar.jpeg}
%	\caption{Bar chart for escaped cases in heterogeneous setting. Shows mean, best and worse for scenarios with one, two and three shepherds herding one sheep}
%	\label{fig:escaped_oneSheep}
%\end{figure}


%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_3v1-hetero_3v2-hetero_3v3-corralledRatio-bar.jpeg}
%	\caption{Bar chart for corralled cases in heterogeneous setting. Shows mean, best and worse for scenarios with three shepherds herding one, two and three sheep}
%	\label{fig:corralled_threeShepherd}
%\end{figure}


%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=3.3in]{imgs/hetero_3v1-hetero_3v2-hetero_3v3-escapedRatio-bar.jpeg}
%	\caption{Bar chart for escaped cases in heterogeneous setting. Shows mean, best and worse for scenarios with three shepherds herding one, two and three sheep}
%	\label{fig:escaped_threeShepherd}
%\end{figure}



\section{Conclusion}
The conclusion goes here.



\bibliographystyle{abbrv}
\bibliography{bibliography}



\end{document}

